<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>DreamEcho - Oyente</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.39/Tone.min.js"></script>
  <style>
    body { font-family: sans-serif; padding: 1em; text-align: center; background-color: #c1f7f2; margin: 0; min-height: 100vh; overflow-x: hidden; overflow-y: auto; }
    .marco { width: 90%; max-width: 600px; margin: 1em auto; padding: 1em; background: white; border: 5px solid blue; border-radius: 1em; box-sizing: border-box; }
    h1 { font-size: 2.5em; margin: 0.2em 0; }
    #recuentoOyentes, #status { font-size: 1.1em; color: #555; margin: 0.5em 0; }
    button { margin: 0.5em; font-size: 1em; padding: 0.8em 1.5em; cursor: pointer; }
    video { width: 100%; max-height: 300px; background: black; border-radius: 0.5em; margin-bottom: 1em; }
    #midiSelectContainer select { margin-top: 1em; padding: 0.5em; font-size: 1em; }
    #chatLog { width: 100%; height: 180px; margin: 1em 0 0.5em; padding: 0.5em; border: 1px solid #ccc; overflow-y: auto; text-align: left; background: #fafafa; border-radius: 0.5em; }
    #chatInput { width: 70%; padding: 0.5em; font-size: 1em; }
    #sendChatBtn { padding: 0.6em 1em; font-size: 1em; margin-left: 0.5em; cursor: pointer; }
    .chat-mensaje-propio { color: blue; }
    .ripple { position: fixed; border-radius: 50%; transform: scale(0); pointer-events: none; animation: rippleAnim 0.8s ease-out forwards; }
    @keyframes rippleAnim { to { transform: scale(15); opacity: 0; } }
  </style>
</head>
<body>
  <div class="marco">
    <h1>DreamEcho - Oyente</h1>
    <p><a href="https://www.youtube.com/@rafgim" target="_blank" rel="noopener">¬© By Rafael Gimeno</a></p>

    <!-- V√≠deo remoto -->
    <video id="remoteVideo" autoplay playsinline controls></video>

    <p id="recuentoOyentes">Oyentes conectados: --</p>
    <p id="status">Esperando conexi√≥n‚Ä¶</p>

    <button onclick="modoMIDI()">üéπ Usar mi piano digital</button>
    <button onclick="modoVirtual()">üéß Escuchar con sonido virtual</button>

    <div id="midiSelectContainer"></div>

    <!-- Chat -->
    <div id="chatControles">
      <div id="chatLog"></div>
      <input id="chatInput" placeholder="Escribe tu mensaje‚Ä¶" />
      <button id="sendChatBtn">üó®Ô∏è Enviar</button>
    </div>
  </div>

  <script>
    // DOM elements
    const statusEl = document.getElementById('status');
    const oyentesEl = document.getElementById('recuentoOyentes');
    const remoteVideo = document.getElementById('remoteVideo');
    const chatLog = document.getElementById('chatLog');
    const chatInput = document.getElementById('chatInput');
    const sendChatBtn = document.getElementById('sendChatBtn');
    const midiSelectContainer = document.getElementById('midiSelectContainer');

    // State
    let firstEventTime = null;
    let startPlaybackTime = null;
    let audioStartTime = null;
    let queuePos = null;
    let queueLatency = null;
    let mode = null;
    let output = null;
    let synth = null;

    // WebSocket and PeerConnection
    const ws = new WebSocket('wss://dreamecho.onrender.com');
    const pc = new RTCPeerConnection({
      iceServers: [
        { urls: 'stun:stun.l.google.com:19302' }
        // Turn server aqu√≠ si lo necesitas
      ]
    });

    // Log ICE connection state
    pc.oniceconnectionstatechange = () => {
      console.log('ICE estado:', pc.iceConnectionState);
    };

    // Send ICE candidates
    pc.onicecandidate = ({ candidate }) => {
      if (candidate) {
        ws.send(JSON.stringify({ type: 'signal', candidate }));
      }
    };

    // Display remote video
    pc.ontrack = ev => {
      console.log('Track remoto recibido', ev.streams);
      remoteVideo.srcObject = ev.streams[0];
    };

    // Receive MIDI channel
    pc.ondatachannel = ev => {
      if (ev.channel.label === 'midi') {
        midiChannel = ev.channel;
        midiChannel.onmessage = ({ data }) => {
          const msg = JSON.parse(data);
          handleMidiMessage(msg);
        };
      }
    };

    // WebSocket events
    ws.onopen = () => {
      console.log('WS abierto');
      statusEl.textContent = 'Conectado, esperando oferta...';
    };

    ws.onmessage = async ({ data }) => {
      const msg = JSON.parse(typeof data === 'string' ? data : await data.text());
      console.log('WS recibido:', msg);

      switch (msg.type) {
        case 'stats':
          oyentesEl.textContent = `Oyentes conectados: ${msg.clients}`;
          if (queuePos === null) {
            queuePos = msg.clients;
            queueLatency = 50 + 5 * Math.sqrt(queuePos);
            statusEl.textContent = `Posici√≥n en cola: ${queuePos} ‚Üí latencia ‚âÉ ${Math.round(queueLatency)} ms`;
          }
          break;

        case 'chat':
          appendChat(msg.user, msg.text);
          break;

        case 'signal':
          if (msg.offer) {
            console.log('Oferta recibida, a√±adiendo transceptor y respondiendo');
            pc.addTransceiver('video', { direction: 'recvonly' });
            await pc.setRemoteDescription(new RTCSessionDescription(msg.offer));
            const answer = await pc.createAnswer();
            await pc.setLocalDescription(answer);
            ws.send(JSON.stringify({ type: 'signal', answer: pc.localDescription }));
          } else if (msg.answer) {
            console.log('Respuesta recibida');
            await pc.setRemoteDescription(new RTCSessionDescription(msg.answer));
          } else if (msg.candidate) {
            console.log('Candidato recibido');
            await pc.addIceCandidate(new RTCIceCandidate(msg.candidate));
          }
          break;
      }
    };

    ws.onerror = err => {
      console.error('WS error:', err);
      statusEl.textContent = 'Error en la conexi√≥n.';
    };
    ws.onclose = () => {
      console.log('WS cerrado');
      statusEl.textContent = 'Conexi√≥n cerrada.';
    };

    // Chat functions
    const username = prompt('¬øC√≥mo quieres que te vean en el chat?', 'Oyente') || 'Oyente';
    function appendChat(user, text) {
      const msgEl = document.createElement('div');
      msgEl.innerHTML = `<small>[${new Date().toLocaleTimeString()}]</small> <strong>${user}:</strong> ${text}`;
      if (user === username) msgEl.classList.add('chat-mensaje-propio');
      chatLog.appendChild(msgEl);
      chatLog.scrollTop = chatLog.scrollHeight;
    }
    function sendChat() {
      const t = chatInput.value.trim();
      if (t && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'chat', user: username, text: t }));
        chatInput.value = '';
      }
    }
    sendChatBtn.addEventListener('click', sendChat);
    chatInput.addEventListener('keydown', e => { if (e.key === 'Enter') sendChat(); });

    // Virtual piano mode
    async function modoVirtual() {
      mode = 'virtual';
      statusEl.textContent = 'Cargando piano virtual‚Ä¶';
      firstEventTime = null;
      await Tone.start();
      synth = new Tone.Sampler({
        urls: { A4: 'A4.mp3' },
        baseUrl: 'https://tonejs.github.io/audio/salamander/',
        release: 0.4,
        onload: () => {
          statusEl.textContent = `Virtual listo. Posici√≥n: ${queuePos} ‚Üí latencia ‚âÉ ${Math.round(queueLatency)} ms`;
        }
      }).toDestination();
    }

    // Physical MIDI mode
    function modoMIDI() {
      mode = 'midi';
      statusEl.textContent = 'Buscando dispositivos MIDI‚Ä¶';
      firstEventTime = null;
      navigator.requestMIDIAccess().then(ma => {
        const outputs = Array.from(ma.outputs.values());
        if (!outputs.length) {
          statusEl.textContent = 'No hay dispositivos MIDI.';
          return;
        }
        midiSelectContainer.innerHTML = '';
        const sel = document.createElement('select');
        sel.innerHTML = '<option value="">-- Elige salida MIDI --</option>';
        outputs.forEach(o => sel.innerHTML += `<option value="${o.id}">${o.name}</option>`);
        sel.onchange = () => {
          output = ma.outputs.get(sel.value);
          statusEl.textContent = `Salida MIDI: ${output.name}`;
        };
        midiSelectContainer.appendChild(sel);
      }).catch(() => {
        statusEl.textContent = 'No se pudo acceder a MIDI.';
      });
    }

    // Handle incoming MIDI messages
    function handleMidiMessage(msg) {
      const [st, note, vel] = msg.data;
      const cmd = st & 0xf0;
      if (firstEventTime === null) {
        firstEventTime = msg.time;
        startPlaybackTime = performance.now() + queueLatency;
        audioStartTime = Tone.now() + queueLatency / 1000;
      }
      const rel = msg.time - firstEventTime;

      // Visual ripple
      if (cmd === 0x90 && vel > 0) {
        const dot = document.createElement('div');
        dot.classList.add('ripple');
        document.body.appendChild(dot);
        setTimeout(() => dot.remove(), 800);
      }

      // Physical MIDI
      if (mode === 'midi' && output) {
        const delay = Math.max(0, startPlaybackTime + rel - performance.now());
        setTimeout(() => output.send(new Uint8Array(msg.data)), delay);
      }

      // Virtual MIDI
      if (mode === 'virtual' && synth) {
        const freq = Tone.Frequency(note, 'midi').toFrequency();
        const t = audioStartTime + rel / 1000;
        if (cmd === 0x90 && vel > 0) synth.triggerAttack(freq, t, vel / 127);
        if (cmd === 0x80 || (cmd === 0x90 && vel === 0)) synth.triggerRelease(freq, t);
      }
    }
  </script>
</body>
</html>
