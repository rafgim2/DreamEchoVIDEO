<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>DreamEcho - Oyente</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.39/Tone.min.js"></script>
  <style>
    body { font-family: sans-serif; padding: 1em; text-align: center; background-color: #c1f7f2; margin: 0; min-height: 100vh; overflow-x: hidden; overflow-y: auto; }
    .marco { width: 90%; max-width: 700px; margin: 1em auto; padding: 1em; background: white; border: 5px solid blue; border-radius: 1em; box-sizing: border-box; }
    h1 { font-size: 2.5em; margin: 0.2em 0; }
    .video-box { display: flex; gap: 1em; justify-content: center; margin-bottom: 1em; }
    .video-wrap { flex: 1; display: flex; flex-direction: column; align-items: center; }
    video { width: 100%; max-height: 250px; background: black; border-radius: 0.5em; }
    .video-wrap span { margin-top: .4em; font-size: .95em; color: #555; }
    #talkStatus { margin-bottom: 1em; font-size:1em; color:#555; }
    #talkBtn {
      background: blue;
      color: white;
      border: none;
      border-radius: .5em;
      font-size: 1.2em;
      padding: .7em 1.7em;
      margin-bottom: 1em;
      cursor: pointer;
      box-shadow: 0 2px 7px rgba(0,0,255,0.2);
      transition: background 0.18s;
    }
    #talkBtn:active { background: #0033aa; }
    #recuentoOyentes, #status { font-size: 1.1em; color: #555; margin: 0.5em 0; }
    button.modeBtn { margin: 0.5em; font-size: 1em; padding: 0.8em 1.5em; cursor: pointer; }
    #midiSelectContainer select { margin-top: 1em; padding: 0.5em; font-size: 1em; }
    #chatLog { width: 100%; height: 180px; margin: 1em 0 0.5em; padding: 0.5em; border: 1px solid #ccc; overflow-y: auto; text-align: left; background: #fafafa; border-radius: 0.5em; }
    #chatInput { width: 70%; padding: 0.5em; font-size: 1em; }
    #sendChatBtn { padding: 0.6em 1em; font-size: 1em; margin-left: 0.5em; cursor: pointer; }
    .chat-mensaje-propio { color: blue; }
    .ripple { position: fixed; border-radius: 50%; transform: scale(0); pointer-events: none; animation: rippleAnim 0.8s ease-out forwards; }
    @keyframes rippleAnim { to { transform: scale(15); opacity: 0; } }
  </style>
</head>
<body>
  <div class="marco">
    <h1>DreamEcho - Oyente</h1>
    <p><a href="https://www.youtube.com/@rafgim" target="_blank" rel="noopener">¬© By Rafael Gimeno</a></p>

    <div class="video-box">
      <div class="video-wrap">
        <video id="localVideo" autoplay muted playsinline></video>
        <span>T√∫</span>
      </div>
      <div class="video-wrap">
        <video id="remoteVideo" autoplay playsinline></video>
        <span>Emisor</span>
      </div>
    </div>

    <div id="talkStatus">Walkie-talkie: Mant√©n pulsado para hablar</div>
    <button id="talkBtn">üîä Hablar</button>

    <p id="recuentoOyentes">Oyentes conectados: --</p>
    <p id="status">Esperando conexi√≥n‚Ä¶</p>

    <button class="modeBtn" onclick="modoMIDI()">üéπ Usar mi piano digital</button>
    <button class="modeBtn" onclick="modoVirtual()">üéß Escuchar con sonido virtual</button>
    <div id="midiSelectContainer"></div>

    <div id="chatControles">
      <div id="chatLog"></div>
      <input id="chatInput" placeholder="Escribe tu mensaje‚Ä¶" />
      <button id="sendChatBtn">üó®Ô∏è Enviar</button>
    </div>
  </div>

  <script>
    // 1) Captura c√°mara y micr√≥fono local al cargar
    let localStream = null;
    (async () => {
      try {
        localStream = await navigator.mediaDevices.getUserMedia({ video: true, audio: true });
        document.getElementById('localVideo').srcObject = localStream;
      } catch (err) {
        alert('Error c√°mara/micro: ' + err.name);
        console.error(err);
      }
    })();

    // 2) Variables globales
    let ws = null, pc = null, midiChannel = null, activeMIDIInput = null;
    let startTime = null, prevClients = 0;
    let remoteStream = null;
    const username = prompt('¬øC√≥mo quieres que te vean en el chat?', 'Oyente') || 'Oyente';

    // Walkie-talkie
    let localAudioTrack = null, isTalking = false, otherIsTalking = false;

    // 3) Iniciar WebSocket
    function initWebSocket() {
      ws = new WebSocket('wss://dreamecho.onrender.com');
      ws.onopen = () => {
        document.getElementById('status').textContent = 'Conectado, esperando oferta...';
      };
      ws.onmessage = async ({ data }) => {
        const msg = JSON.parse(typeof data === 'string' ? data : await data.text());
        if (msg.type === 'stats') {
          document.getElementById('recuentoOyentes').textContent = `Oyentes conectados: ${msg.clients}`;
        }
        if (msg.type === 'chat') appendChat(msg.user, msg.text);
        if (msg.type === 'signal') await handleSignal(msg);
      };
      ws.onerror = () => { document.getElementById('status').textContent = 'Error en la conexi√≥n.'; };
      ws.onclose = () => { document.getElementById('status').textContent = 'Conexi√≥n cerrada.'; };
    }

    function sendSignal(data) {
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'signal', ...data }));
      }
    }

    // 4) Iniciar / renegociar WebRTC
    async function startWebRTC() {
      // Cerrar conexi√≥n anterior
      if (pc) try { pc.close(); } catch {}
      pc = new RTCPeerConnection({ iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] });

      // ICE
      pc.onicecandidate = ({ candidate }) => { if (candidate) sendSignal({ candidate }); };

      // Prepara remoteStream
      remoteStream = new MediaStream();
      document.getElementById('remoteVideo').srcObject = remoteStream;
      pc.ontrack = ev => {
        if (!remoteStream.getTracks().find(t => t.id === ev.track.id)) {
          remoteStream.addTrack(ev.track);
        }
      };

      // DataChannel (si el artista lo cre√≥ primero)
      pc.ondatachannel = ev => {
        if (ev.channel.label === 'midi') {
          midiChannel = ev.channel;
          midiChannel.onmessage = handleDataChannelMessage;
        }
      };

      // A√±adir tracks locales
      if (localStream) {
        // Track para walkie
        localAudioTrack = localStream.getAudioTracks()[0];
        if (localAudioTrack) localAudioTrack.enabled = false;
        localStream.getTracks().forEach(track => {
          if (!pc.getSenders().find(s => s.track && s.track.id === track.id)) {
            pc.addTrack(track, localStream);
          }
        });
      }

      // Crear canal MIDI si no existe
      if (!midiChannel || midiChannel.readyState === 'closed') {
        midiChannel = pc.createDataChannel('midi');
        midiChannel.onmessage = handleDataChannelMessage;
      }

      // Oferta / respuesta
      if (ws && ws.readyState === WebSocket.OPEN) {
        const offer = await pc.createOffer();
        await pc.setLocalDescription(offer);
        sendSignal({ offer: pc.localDescription });
      }
    }

    // 5) Manejo se√±alizaci√≥n
    async function handleSignal(msg) {
      if (msg.offer) {
        await startWebRTC();               // en caso de que no hayamos arrancado
        await pc.setRemoteDescription(new RTCSessionDescription(msg.offer));
        const answer = await pc.createAnswer();
        await pc.setLocalDescription(answer);
        sendSignal({ answer: pc.localDescription });
      }
      if (msg.answer) {
        await pc.setRemoteDescription(new RTCSessionDescription(msg.answer));
      }
      if (msg.candidate) {
        await pc.addIceCandidate(new RTCIceCandidate(msg.candidate));
      }
    }

    // 6) Chat
    function appendChat(user, text) {
      const log = document.getElementById('chatLog');
      const msgEl = document.createElement('div');
      const time = new Date().toLocaleTimeString();
      if (user === username) msgEl.classList.add('chat-mensaje-propio');
      msgEl.innerHTML = `<small>[${time}]</small> <strong>${user}:</strong> ${text}`;
      log.appendChild(msgEl);
      log.scrollTop = log.scrollHeight;
    }
    document.getElementById('sendChatBtn').addEventListener('click', () => {
      const t = document.getElementById('chatInput').value.trim();
      if (t && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'chat', user: username, text: t }));
        document.getElementById('chatInput').value = '';
      }
    });
    document.getElementById('chatInput').addEventListener('keydown', e => {
      if (e.key === 'Enter') document.getElementById('sendChatBtn').click();
    });

    // 7) MIDI Oyente (igual que antes)
    function modoMIDI() {
      document.getElementById('status').textContent = 'Buscando dispositivos MIDI‚Ä¶';
      navigator.requestMIDIAccess().then(ma => {
        const outputs = Array.from(ma.outputs.values());
        if (!outputs.length) { document.getElementById('status').textContent = 'No hay dispositivos MIDI.'; return; }
        const c = document.getElementById('midiSelectContainer');
        c.innerHTML = '';
        const sel = document.createElement('select');
        sel.innerHTML = '<option value="">-- Elige salida MIDI --</option>';
        outputs.forEach(o => sel.innerHTML += `<option value="${o.id}">${o.name}</option>`);
        sel.onchange = () => { activeMIDIInput = ma.outputs.get(sel.value); document.getElementById('status').textContent = `Salida MIDI: ${activeMIDIInput.name}`; };
        c.appendChild(sel);
      }).catch(() => { document.getElementById('status').textContent = 'No se pudo acceder a MIDI.'; });
    }

    let synth = null, pedal = false, notasActivas = new Set(), notasSostenidas = new Set();
    async function modoVirtual() {
      document.getElementById('status').textContent = 'Cargando piano virtual‚Ä¶';
      pedal = false; notasActivas.clear(); notasSostenidas.clear();
      await Tone.start();
      synth = new Tone.Sampler({
        urls: { A0: 'A0.mp3', C1: 'C1.mp3', 'D#1': 'Ds1.mp3', F#1: 'Fs1.mp3',
                A1: 'A1.mp3', C2: 'C2.mp3', 'D#2': 'Ds2.mp3', F#2: 'Fs2.mp3',
                A2: 'A2.mp3', C3: 'C3.mp3', 'D#3': 'Ds3.mp3', F#3: 'Fs3.mp3',
                A3: 'A3.mp3', C4: 'C4.mp3', 'D#4': 'Ds4.mp3', F#4: 'Fs4.mp3',
                A4: 'A4.mp3', C5: 'C5.mp3', 'D#5': 'Ds5.mp3', F#5: 'Fs5.mp3',
                A5: 'A5.mp3', C6: 'C6.mp3', 'D#6': 'Ds6.mp3', F#6: 'Fs6.mp3',
                A7: 'A7.mp3', C8: 'C8.mp3' },
        baseUrl: 'https://tonejs.github.io/audio/salamander/',
        release: 0.4,
        onload: () => { document.getElementById('status').textContent = 'Modo virtual listo.'; }
      }).toDestination();
    }

    function handleMidiMessage(msg) {
      const [st, note, vel] = msg.data;
      const cmd = st & 0xf0;
      if (cmd === 0x90 && vel > 0) {
        const dot = document.createElement('div'); dot.classList.add('ripple'); document.body.appendChild(dot);
        setTimeout(() => dot.remove(), 800);
      }
      if (activeMIDIInput) activeMIDIInput.send(new Uint8Array(msg.data));
      if (synth) {
        const freq = Tone.Frequency(note, 'midi').toFrequency();
        if (cmd === 0x90 && vel > 0) {
          const velN = vel / 127, velS = velN * velN;
          synth.triggerAttack(freq, Tone.now(), velS);
          notasActivas.add(freq); notasSostenidas.delete(freq);
        } else if (cmd === 0x80 || (cmd===0x90&&vel===0)) {
          if (pedal) { notasActivas.delete(freq); notasSostenidas.add(freq); }
          else { synth.triggerRelease(freq, Tone.now()); notasActivas.delete(freq); notasSostenidas.delete(freq); }
        } else if (st===176 && note===64) {
          pedal = vel>=64;
          if (!pedal) notasSostenidas.forEach(f=>{synth.triggerRelease(f,Tone.now()); notasSostenidas.delete(f);});
        }
      }
    }

    // 8) Walkie-talkie
    function setTalkStatus() {
      const st = document.getElementById('talkStatus');
      if (isTalking) st.innerHTML = `<b>Est√°s hablando</b> (micr√≥fono activo)`;
      else if (otherIsTalking) st.innerHTML = `<b>El Emisor est√° hablando</b> (su micro silenciado)`;
      else st.innerHTML = `Walkie-talkie: Mant√©n pulsado para hablar`;
    }
    function sendWalkieSignal(talking) {
      if (midiChannel && midiChannel.readyState==='open') {
        midiChannel.send(JSON.stringify({ type:'walkie', talking }));
      }
    }
    function handleDataChannelMessage(ev) {
      try {
        const msg = JSON.parse(ev.data);
        if (msg.type==='walkie') {
          otherIsTalking = msg.talking;
          // silencia al emisor
          const tracks = remoteStream?.getAudioTracks()||[];
          tracks.forEach(t=> t.enabled = !otherIsTalking);
          setTalkStatus();
        }
        if (msg.type==='midi') handleMidiMessage(msg);
      } catch {}
    }
    const talkBtn = document.getElementById('talkBtn');
    talkBtn.addEventListener('mousedown', () => {
      isTalking = true;
      if (localAudioTrack) localAudioTrack.enabled = true;
      sendWalkieSignal(true);
      setTalkStatus();
    });
    talkBtn.addEventListener('mouseup', () => {
      isTalking = false;
      if (localAudioTrack) localAudioTrack.enabled = false;
      sendWalkieSignal(false);
      setTalkStatus();
    });
    ['mouseleave','touchend','touchcancel'].forEach(evt=>
      talkBtn.addEventListener(evt, ()=>{
        isTalking=false;
        if(localAudioTrack)localAudioTrack.enabled=false;
        sendWalkieSignal(false);
        setTalkStatus();
      })
    );

    // 9) Arranca todo
    initWebSocket();
    // Y cuando recibas la primera se√±al de stats, lanza startWebRTC
    ws?.addEventListener('message', ({data})=>{
      const m=JSON.parse(data);
      if(m.type==='stats') startWebRTC();
    });
  </script>
</body>
</html>
