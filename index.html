<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>DreamEcho - Oyente</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.39/Tone.min.js"></script>
  <style>
    html, body { height:100%; margin:0; font-family:sans-serif; background-color:#c1f7f2; }
    body { display:flex; justify-content:center; align-items:center; padding:1em; }
    .marco { width:90%; max-width:700px; background:white; border:5px solid blue; border-radius:1em; padding:1em; box-sizing:border-box; text-align:center; }
    h1 { font-size:2.5em; margin:0.2em 0; }
    .video-container { display:flex; gap:1em; justify-content:center; flex-wrap:wrap; margin:1em 0; }
    .video-block { flex:1 1 calc(50% - 1em); display:flex; flex-direction:column; align-items:center; }
    .video-block video { width:100%; max-height:250px; background:black; border-radius:0.5em; }
    .video-label { margin-top:0.3em; font-weight:bold; color:#333; }
    #talkBtn { display:block; margin:0 auto 1.5em; padding:0.8em 2em; font-size:1.1em; border:2px solid #2196f3; border-radius:0.7em; background:#2196f3; color:#fff; cursor:pointer; user-select:none; transition:background 0.2s, border-color 0.2s; }
    #talkBtn.talking, #talkBtn:active { background:red; border-color:darkred; }
    .midi-section { margin:1em 0; }
    #recuentoOyentes, #status { font-size:1.1em; color:#555; margin:0.5em 0; }
  </style>
</head>
<body>
  <div class="marco">
    <h1>DreamEcho - Oyente</h1>
    <p><a href="https://www.youtube.com/@rafgim" target="_blank" rel="noopener">Â© By Rafael Gimeno</a></p>

    <div class="video-container">
      <div class="video-block">
        <video id="localVideo" autoplay muted playsinline></video>
        <p class="video-label">TÃº</p>
      <//div>
      <div class="video-block">
        <video id="remoteVideo" autoplay playsinline></video>
        <p class="video-label">Artista</p>
      </div>
    </div>

    <button id="talkBtn">ðŸ“¢ MantÃ©n pulsado para hablar</button>

    <div class="midi-section">
      <h3>MIDI recibido (del artista):</h3>
      <button id="midiOutBtn">ðŸŽ¹ Usar mi piano digital</button>
      <button id="virtualBtn">ðŸŽ§ Usar sonido virtual</button>
      <div id="midiOutSelectCont"></div>
      <div id="midiStatus"></div>
    </div>
    <div class="midi-section">
      <h3>MIDI a enviar (tu piano):</h3>
      <div id="midiInSelectCont"></div>
      <div id="midiSendStatus"></div>
    </div>

    <p id="recuentoOyentes">Oyentes conectados: --</p>
    <p id="status">Esperando conexiÃ³nâ€¦</p>
  </div>

  <script>
    const ws = new WebSocket('wss://dreamecho.onrender.com');
    const pc = new RTCPeerConnection({ iceServers:[{ urls:'stun:stun.l.google.com:19302' }] });
    const localVideo = document.getElementById('localVideo');
    const remoteVideo = document.getElementById('remoteVideo');
    const talkBtn = document.getElementById('talkBtn');
    const statusEl = document.getElementById('status');
    const oyentesEl = document.getElementById('recuentoOyentes');
    const midiOutBtn = document.getElementById('midiOutBtn');
    const virtualBtn = document.getElementById('virtualBtn');
    const midiOutSelectCont = document.getElementById('midiOutSelectCont');
    const midiInSelectCont = document.getElementById('midiInSelectCont');
    const midiStatus = document.getElementById('midiStatus');
    const midiSendStatus = document.getElementById('midiSendStatus');

    let localStream, realAudioTrack, silentAudioTrack, audioSender;
    let pressingTalk = false, remoteSpeaking = false;
    let midiAccess, midiInputs = [], midiOutputs = [], midiOutDevice, midiInDevice, midiChannel;
    let synth, useVirtual = true;

    function createSilentAudioTrack() {
      const ctx = new (window.AudioContext || window.webkitAudioContext)();
      const osc = ctx.createOscillator(); osc.frequency.value = 0;
      const dst = osc.connect(ctx.createMediaStreamDestination());
      osc.start(); setTimeout(() => osc.stop(), 100);
      return dst.stream.getAudioTracks()[0];
    }

    async function initLocalVideo() {
      if (localStream) return;
      try {
        localStream = await navigator.mediaDevices.getUserMedia({ video:true, audio:true });
        localVideo.srcObject = localStream;
        realAudioTrack = localStream.getAudioTracks()[0];
        silentAudioTrack = createSilentAudioTrack();
        localStream.getTracks().forEach(track => {
          const sender = pc.addTrack(track, localStream);
          if (track.kind === 'audio') audioSender = sender;
        });
        audioSender.replaceTrack(silentAudioTrack);
      } catch (e) {
        statusEl.textContent = 'âš ï¸ No se pudo acceder a cÃ¡mara/micro.';
      }
    }
    initLocalVideo();

    function updateMicState() {
      if (!audioSender) return;
      const active = pressingTalk && !remoteSpeaking;
      audioSender.replaceTrack(active ? realAudioTrack : silentAudioTrack);
      talkBtn.classList.toggle('talking', active);
    }

    function pressTalk() {
      pressingTalk = true;
      ws.send(JSON.stringify({ type:'talk', speaking:true }));
      updateMicState();
    }
    function releaseTalk() {
      pressingTalk = false;
      ws.send(JSON.stringify({ type:'talk', speaking:false }));
      updateMicState();
    }
    ['mousedown','touchstart'].forEach(e => talkBtn.addEventListener(e, pressTalk));
    ['mouseup','mouseleave','touchend','touchcancel'].forEach(e => talkBtn.addEventListener(e, releaseTalk));

    function sendSignal(d) {
      ws.send(JSON.stringify({ type:'signal', ...d }));
    }

    ws.onopen = () => { statusEl.textContent = 'Conectado'; startWebRTC(); setupMIDI(); setupSampler(); };
    ws.onmessage = async ({ data }) => {
      const msg = JSON.parse(data);
      switch (msg.type) {
        case 'stats':
          oyentesEl.textContent = `Oyentes conectados: ${msg.clients}`;
          if (msg.clients > 0) startWebRTC();
          break;
        case 'talk':
          remoteSpeaking = msg.speaking; updateMicState();
          break;
        case 'signal':
          if (msg.offer) {
            await pc.setRemoteDescription(new RTCSessionDescription(msg.offer));
            const answer = await pc.createAnswer();
            await pc.setLocalDescription(answer);
            sendSignal({ answer: pc.localDescription });
          } else if (msg.answer) {
            await pc.setRemoteDescription(new RTCSessionDescription(msg.answer));
          } else if (msg.candidate) {
            await pc.addIceCandidate(new RTCIceCandidate(msg.candidate));
          }
          break;
      }
    };
    ws.onerror = () => statusEl.textContent = 'Error conexiÃ³n';
    ws.onclose = () => statusEl.textContent = 'ConexiÃ³n cerrada';

    pc.onicecandidate = ({ candidate }) => { if (candidate) sendSignal({ candidate }); };
    pc.ontrack = ev => { remoteVideo.srcObject = ev.streams[0]; };
    pc.ondatachannel = ev => {
      if (ev.channel.label === 'midi') {
        midiChannel = ev.channel;
        midiChannel.onmessage = async ({ data }) => await handleMidiMessage(JSON.parse(data), 'artista');
      }
    };

    async function startWebRTC() {
      if (!localStream) await initLocalVideo();
      const offer = await pc.createOffer();
      await pc.setLocalDescription(offer);
      sendSignal({ offer: pc.localDescription });
    }

    async function setupMIDI() {
      try {
        midiAccess = await navigator.requestMIDIAccess();
        midiInputs = Array.from(midiAccess.inputs.values());
        midiOutputs = Array.from(midiAccess.outputs.values());
        midiOutSelectCont.innerHTML = '';
        if (midiOutputs.length) {
          const sel = document.createElement('select');
          sel.innerHTML = '<option value="">-- Salida MIDI --</option>';
          midiOutputs.forEach((o, i) => sel.innerHTML += `<option value="${i}">${o.name}</option>`);
          sel.onchange = () => {
            midiOutDevice = sel.value ? midiOutputs[+sel.value] : null;
            useVirtual = !midiOutDevice;
            midiStatus.textContent = midiOutDevice ? `MIDI OUT: ${midiOutDevice.name}` : 'Sonido virtual';
          };
          midiOutSelectCont.appendChild(sel);
        }
        midiInSelectCont.innerHTML = '';
        if (midiInputs.length) {
          const selIn = document.createElement('select');
          selIn.innerHTML = '<option value="">-- Entrada MIDI --</option>';
          midiInputs.forEach((i, k) => selIn.innerHTML += `<option value="${k}">${i.name}</option>`);
          selIn.onchange = () => {
            if (midiInDevice) midiInDevice.onmidimessage = null;
            midiInDevice = selIn.value ? midiInputs[+selIn.value] : null;
            if (midiInDevice) {
              midiInDevice.onmidimessage = ({ data }) => {
                if (midiChannel && midiChannel.readyState === 'open')
                  midiChannel.send(JSON.stringify({ data: Array.from(data), from: 'oyente' }));
              };
              midiSendStatus.textContent = `Enviando MIDI desde: ${midiInDevice.name}`;
            }
          };
          midiInSelectCont.appendChild(selIn);
        }
      } catch (e) {
        midiStatus.textContent = 'No acceso a MIDI';
      }
    }

    async function setupSampler() {
      if (synth) return;
      await Tone.start();
      synth = new Tone.Sampler({
        urls: { A0:'A0.mp3',C1:'C1.mp3','D#1':'Ds1.mp3','F#1':'Fs1.mp3',A1:'A1.mp3',C2:'C2.mp3','D#2':'Ds2.mp3','F#2':'Fs2.mp3',A2:'A2.mp3',C3:'C3.mp3','D#3':'Ds3.mp3','F#3':'Fs3.mp3',A3:'A3.mp3',C4:'C4.mp3','D#4':'Ds4.mp3','F#4':'Fs4.mp3',A4:'A4.mp3',C5:'C5.mp3','D#5':'Ds5.mp3','F#5':'Fs5.mp3',A5:'A5.mp3',C6:'C6.mp3','D#6':'Ds6.mp3','F#6':'Fs6.mp3',A7:'A7.mp3',C8:'C8.mp3' },
        baseUrl:'https://tonejs.github.io/audio/salamander/', release:0.4,
        onload:()=> midiStatus.textContent='Sampler listo'
      }).toDestination();
    }

    async function handleMidiMessage(msg, origin) {
      const [st, note, vel] = msg.data;
      const cmd = st & 0xf0;
      if (!useVirtual && midiOutDevice) {
        midiOutDevice.send(new Uint8Array(msg.data));
      } else {
        if (!synth) await setupSampler();
        const freq = Tone.Frequency(note, 'midi').toFrequency();
        if (cmd === 0x90 && vel > 0) synth.triggerAttack(freq, Tone.now(), Math.pow(vel/127,2));
        else if (cmd === 0x80 || (cmd===0x90 && vel===0)) synth.triggerRelease(freq, Tone.now());
      }
    }

  </script>
</body>
</html>
