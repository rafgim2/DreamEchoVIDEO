<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8">
  <title>DreamEcho - Oyente</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/tone/14.8.39/Tone.min.js"></script>
  <style>
    body { font-family: sans-serif; padding: 1em; text-align: center; background-color: #c1f7f2; margin: 0; min-height: 100vh; overflow-x: hidden; overflow-y: auto; }
    .marco { width: 90%; max-width: 600px; margin: 1em auto; padding: 1em; background: white; border: 5px solid blue; border-radius: 1em; box-sizing: border-box; }
    h1 { font-size: 2.5em; margin: 0.2em 0; }
    #recuentoOyentes, #status { font-size: 1.1em; color: #555; margin: 0.5em 0; }
    button { margin: 0.5em; font-size: 1em; padding: 0.8em 1.5em; cursor: pointer; }
    video { width: 100%; max-height: 300px; background: black; border-radius: 0.5em; margin-bottom: 1em; }
    #midiSelectContainer select { margin-top: 1em; padding: 0.5em; font-size: 1em; }
    #chatLog { width: 100%; height: 180px; margin: 1em 0 0.5em; padding: 0.5em; border: 1px solid #ccc; overflow-y: auto; text-align: left; background: #fafafa; border-radius: 0.5em; }
    #chatInput { width: 70%; padding: 0.5em; font-size: 1em; }
    #sendChatBtn { padding: 0.6em 1em; font-size: 1em; margin-left: 0.5em; cursor: pointer; }
    .chat-mensaje-propio { color: blue; }
    .ripple { position: fixed; border-radius: 50%; transform: scale(0); pointer-events: none; animation: rippleAnim 0.8s ease-out forwards; }
    @keyframes rippleAnim { to { transform: scale(15); opacity: 0; } }
  </style>
</head>
<body>
  <div class="marco">
    <h1>DreamEcho - Oyente</h1>
    <p><a href="https://www.youtube.com/@rafgim" target="_blank" rel="noopener">¬© By Rafael Gimeno</a></p>

    <!-- V√≠deo remoto -->
    <video id="remoteVideo" autoplay playsinline controls></video>

    <p id="recuentoOyentes">Oyentes conectados: --</p>
    <p id="status">Esperando conexi√≥n‚Ä¶</p>

    <button onclick="modoMIDI()">üéπ Usar mi piano digital</button>
    <button onclick="modoVirtual()">üéß Escuchar con sonido virtual</button>

    <div id="midiSelectContainer"></div>

    <!-- Chat -->
    <div id="chatControles">
      <div id="chatLog"></div>
      <input id="chatInput" placeholder="Escribe tu mensaje‚Ä¶" />
      <button id="sendChatBtn">üó®Ô∏è Enviar</button>
    </div>
  </div>

  <script>
    const statusEl = document.getElementById('status');
    const oyentesEl = document.getElementById('recuentoOyentes');
    const remoteVideo = document.getElementById('remoteVideo');
    const chatLog = document.getElementById('chatLog');
    const chatInput = document.getElementById('chatInput');
    const sendChatBtn = document.getElementById('sendChatBtn');
    const midiSelectContainer = document.getElementById('midiSelectContainer');

    let firstEventTime = null;
    let startPlaybackTime = null;
    let audioStartTime = null;
    let queuePos = null;
    let queueLatency = null;
    let mode = null;
    let output = null;
    let synth = null;
    let pedal = false;
    const notasActivas = new Set();
    const notasSostenidas = new Set();

    const ws = new WebSocket('wss://dreamecho.onrender.com');
    const pc = new RTCPeerConnection({ iceServers: [{ urls: 'stun:stun.l.google.com:19302' }] });
    let midiChannel = null;

    pc.onicecandidate = ({ candidate }) => {
      if (candidate) ws.send(JSON.stringify({ type: 'signal', candidate }));
    };
    pc.ontrack = ev => {
      remoteVideo.srcObject = ev.streams[0];
    };
    pc.ondatachannel = ev => {
      if (ev.channel.label === 'midi') {
        midiChannel = ev.channel;
        midiChannel.onmessage = ({ data }) => {
          const msg = JSON.parse(data);
          handleMidiMessage(msg);
        };
      }
    };

    ws.onopen = () => { statusEl.textContent = 'Conectado al servidor, esperando oferta...'; };
    ws.onmessage = async ({ data }) => {
      const msg = JSON.parse(typeof data === 'string' ? data : await data.text());
      switch (msg.type) {
        case 'stats':
          oyentesEl.textContent = `Oyentes conectados: ${msg.clients}`;
          if (queuePos === null) {
            queuePos = msg.clients;
            queueLatency = 50 + 5 * Math.sqrt(queuePos);
            statusEl.textContent = `Posici√≥n en cola: ${queuePos} ‚Üí latencia ‚âÉ ${Math.round(queueLatency)} ms`;
          }
          break;
        case 'chat':
          appendChat(msg.user, msg.text);
          break;
        case 'signal':
          if (msg.offer) {
            pc.addTransceiver('video', { direction: 'recvonly' });
            await pc.setRemoteDescription(new RTCSessionDescription(msg.offer));
            const answer = await pc.createAnswer();
            await pc.setLocalDescription(answer);
            ws.send(JSON.stringify({ type: 'signal', answer: pc.localDescription }));
          } else if (msg.answer) {
            await pc.setRemoteDescription(new RTCSessionDescription(msg.answer));
          } else if (msg.candidate) {
            await pc.addIceCandidate(new RTCIceCandidate(msg.candidate));
          }
          break;
      }
    };
    ws.onerror = () => { statusEl.textContent = 'Error en la conexi√≥n.'; };
    ws.onclose = () => { statusEl.textContent = 'Conexi√≥n cerrada.'; };

    const username = prompt('¬øC√≥mo quieres que te vean en el chat?', 'Oyente') || 'Oyente';
    function appendChat(user, text) {
      const msgEl = document.createElement('div');
      msgEl.innerHTML = `<small>[${new Date().toLocaleTimeString()}]</small> <strong>${user}:</strong> ${text}`;
      if (user === username) msgEl.classList.add('chat-mensaje-propio');
      chatLog.appendChild(msgEl);
      chatLog.scrollTop = chatLog.scrollHeight;
    }
    function sendChat() {
      const t = chatInput.value.trim();
      if (t && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: 'chat', user: username, text: t }));
        chatInput.value = '';
      }
    }
    sendChatBtn.addEventListener('click', sendChat);
    chatInput.addEventListener('keydown', e => { if (e.key === 'Enter') sendChat(); });

    function modoMIDI() {
      mode = 'midi';
      statusEl.textContent = 'Buscando dispositivos MIDI‚Ä¶';
      firstEventTime = null;
      navigator.requestMIDIAccess().then(ma => {
        const outputs = Array.from(ma.outputs.values());
        if (!outputs.length) {
          statusEl.textContent = 'No hay dispositivos MIDI.';
          return;
        }
        midiSelectContainer.innerHTML = '';
        const sel = document.createElement('select');
        sel.innerHTML = '<option value="">-- Elige salida MIDI --</option>';
        outputs.forEach(o => {
          sel.innerHTML += `<option value="${o.id}">${o.name}</option>`;
        });
        sel.onchange = () => {
          output = ma.outputs.get(sel.value);
          statusEl.textContent = `Salida MIDI: ${output.name}`;
        };
        sel.value = outputs[0].id;
        sel.dispatchEvent(new Event('change'));
        midiSelectContainer.appendChild(sel);
      }).catch(() => { statusEl.textContent = 'No se pudo acceder a MIDI.'; });
    }

    async function modoVirtual() {
      mode = 'virtual';
      statusEl.textContent = 'Cargando piano virtual‚Ä¶';
      firstEventTime = null;
      pedal = false;
      notasActivas.clear();
      notasSostenidas.clear();
      await Tone.start();
      synth = new Tone.Sampler({
        urls: { A0: 'A0.mp3', C1: 'C1.mp3', 'D#1': 'Ds1.mp3', 'F#1': 'Fs1.mp3',
                A1: 'A1.mp3', C2: 'C2.mp3', 'D#2': 'Ds2.mp3', 'F#2': 'Fs2.mp3',
                A2: 'A2.mp3', C3: 'C3.mp3', 'D#3': 'Ds3.mp3', 'F#3': 'Fs3.mp3',
                A3: 'A3.mp3', C4: 'C4.mp3', 'D#4': 'Ds4.mp3', 'F#4': 'Fs4.mp3',
                A4: 'A4.mp3', C5: 'C5.mp3', 'D#5': 'Ds5.mp3', 'F#5': 'Fs5.mp3',
                A5: 'A5.mp3', C6: 'C6.mp3', 'D#6': 'Ds6.mp3', 'F#6': 'Fs6.mp3',
                A7: 'A7.mp3', C8: 'C8.mp3' },
        baseUrl: 'https://tonejs.github.io/audio/salamander/',
        release: 0.4,
        onload: () => {
          statusEl.textContent = `Modo virtual listo. Posici√≥n: ${queuePos} ‚Üí latencia ‚âÉ ${Math.round(queueLatency)} ms`;
        }
      }).toDestination();
    }

    function handleMidiMessage(msg) {
      const [st, note, vel] = msg.data;
      const command = st & 0xf0;
      const eventTime = msg.time;
      if (firstEventTime === null) {
        firstEventTime = eventTime;
        startPlaybackTime = performance.now() + queueLatency;
        audioStartTime = Tone.now() + queueLatency / 1000;
      }
      const relative = eventTime - firstEventTime;
      const timeSec = audioStartTime + relative / 1000;

      // Visual ripple
      if (command === 0x90 && vel > 0) {
        const dot = document.createElement('div'); dot.classList.add('ripple'); document.body.appendChild(dot);
        setTimeout(() => dot.remove(), 800);
      }

      // Physical MIDI output
      if (mode === 'midi' && output) {
        const delay = Math.max(0, startPlaybackTime + relative - performance.now());
        setTimeout(() => output.send(new Uint8Array(msg.data)), delay);
      }

      // Virtual piano
      if (mode === 'virtual' && synth) {
        if (command === 0x90 && vel > 0) {
          const velNorm = vel / 127;
          const velScaled = Math.pow(velNorm, 2);
          const freq = Tone.Frequency(note, 'midi').toFrequency();
          synth.triggerAttack(freq, timeSec, velScaled);
          notasActivas.add(freq);
          notasSostenidas.delete(freq);
        } else if (command === 0x80 || (command === 0x90 && vel === 0)) {
          const freq = Tone.Frequency(note, 'midi').toFrequency();
          if (pedal) {
            notasActivas.delete(freq);
            notasSostenidas.add(freq);
          } else {
            synth.triggerRelease(freq, timeSec);
            notasActivas.delete(freq);
            notasSostenidas.delete(freq);
          }
        } else if (st === 176 && note === 64) {
          const isDown = vel >= 64;
          if (isDown) pedal = true;
          else {
            pedal = false;
            notasSostenidas.forEach(f => {
              if (!notasActivas.has(f)) {
                synth.triggerRelease(f, timeSec);
                notasSostenidas.delete(f);
              }
            });
          }
        }
      }
    }
  </script>
</body>
</html>
